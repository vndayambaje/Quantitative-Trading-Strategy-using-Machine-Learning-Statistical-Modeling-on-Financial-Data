{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quantitative Trading Strategy Using Machine Learning**\n",
    "\n",
    "## **Introduction**:\n",
    "The **Quantitative Trading Strategy** project applies machine learning and data-driven insights to optimize trading decisions in the stock market. Utilizing historical financial data from the S&P 500, this project builds predictive models to forecast stock price movements and generate buy/sell signals. By integrating machine learning techniques, this system automates the analysis of large datasets, allowing for the development of effective trading strategies that aim to outperform traditional benchmarks.\n",
    "\n",
    "### **Project Description**:\n",
    "QuantStock is a stock performance evaluation and benchmarking system that analyzes the historical performance of selected S&P 500 stocks and compares them against a market benchmark. Using machine learning models, QuantStock calculates financial metrics, backtests trading strategies, and generates reports that help investors optimize their stock portfolios based on historical data and risk-adjusted returns.\n",
    "\n",
    "### **Key Questions**\n",
    "\n",
    "1. How can stock performance be benchmarked against the S&P 500 using machine learning models?\n",
    "2. Which technical indicators can improve stock price prediction accuracy?\n",
    "3. What are the most effective machine learning models for stock market analysis (RandomForest, XGBoost, LSTM)?\n",
    "4. How can automated reporting and visualization aid decision-making for investors?\n",
    "\n",
    "### **Technologies**\n",
    "\n",
    "- Python (Pandas, Scikit-learn, yFinance, TensorFlow)\n",
    "- Machine Learning (RandomForest, XGBoost, LSTM)\n",
    "- Financial Indicators (SMA, EMA, RSI)\n",
    "- Data Visualization (Matplotlib, Seaborn)\n",
    "- Automated Reporting (FPDF for generating reports)\n",
    "\n",
    "### **The system includes**:\n",
    "\n",
    "**Predictive Model for Stock Movements**:\n",
    "Utilizes machine learning models (Random Forest, XGBoost, LSTM) to predict stock price trends and generate actionable buy/sell signals for S&P 500 stocks.\n",
    "\n",
    "**Technical Indicators**:\n",
    "Incorporates essential technical analysis metrics such as Simple Moving Average (SMA), Exponential Moving Average (EMA), and Relative Strength Index (RSI) to support more informed trading decisions and improve prediction accuracy.\n",
    "\n",
    "**Backtesting and Portfolio Simulation**:\n",
    "Simulates the historical performance of the trading strategy using backtesting techniques, allowing users to assess key financial metrics like Sharpe Ratio, Cumulative Returns, and Maximum Drawdown.\n",
    "\n",
    "**Financial Metrics**:\n",
    "Analyzes the risk and return of the trading strategy through key financial indicators, including volatility, Sharpe Ratio, and risk-adjusted returns, to help traders evaluate profitability and manage risk effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vic3/github/Quantitative-Trading-Strategy-using-Machine-Learning-Statistical-Modeling-on-Financial-Data/Quantitative_Trading_Strategy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/vic3/github/Quantitative-Trading-Strategy-using-Machine-Learning-Statistical-Modeling-on-Financial-Data/Quantitative_Trading_Strategy\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vic3/github/Quantitative-Trading-Strategy-using-Machine-Learning-Statistical-Modeling-on-Financial-Data/Quantitative_Trading_Strategy/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "! pip install -r '/home/vic3/github/Quantitative-Trading-Strategy-using-Machine-Learning-Statistical-Modeling-on-Financial-Data/Quantitative_Trading_Strategy/requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. Import necessary libraries and scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at yiyanghkust/finbert-tone were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at yiyanghkust/finbert-tone.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: [{'label': 'Positive', 'score': 0.9999997615814209}]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import talib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scripts.fetch_stock_data import fetch_stock_data\n",
    "from scripts.models import train_random_forest, train_xgboost, train_lstm_model, scale_features\n",
    "from scripts.backtest_strategy import generate_signals, backtest_strategy\n",
    "from scripts.generate_report import generate_report\n",
    "from scripts.sentiment_analysis import get_sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the stock symbols and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch live stock data\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'SPY']\n",
    "start_date = \"2018-01-01\"\n",
    "initial_balance = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fetch stock data and perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock_data = fetch_stock_data(symbols, start_date=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
      "Date                                                                           \n",
      "2018-01-02  42.540001  43.075001  42.314999  43.064999  40.568924  102223600   \n",
      "2018-01-03  43.132500  43.637501  42.990002  43.057499  40.561871  118071600   \n",
      "2018-01-04  43.134998  43.367500  43.020000  43.257500  40.750282   89738400   \n",
      "2018-01-05  43.360001  43.842499  43.262501  43.750000  41.214230   94640000   \n",
      "2018-01-08  43.587502  43.902500  43.482498  43.587502  41.061142   82271200   \n",
      "\n",
      "            SMA_20  RSI  \n",
      "Date                     \n",
      "2018-01-02     NaN  NaN  \n",
      "2018-01-03     NaN  NaN  \n",
      "2018-01-04     NaN  NaN  \n",
      "2018-01-05     NaN  NaN  \n",
      "2018-01-08     NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "# Display stock data to verify\n",
    "print(stock_data['AAPL'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sentiment Analysis (Optional - Using FinBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Result: [{'label': 'Positive', 'score': 0.9999997615814209}]\n"
     ]
    }
   ],
   "source": [
    "# Example of analyzing sentiment from a news article\n",
    "news_article = \"The company's stock surged after reporting record earnings.\"\n",
    "sentiment_result = get_sentiment(news_article)\n",
    "print(f\"Sentiment Analysis Result: {sentiment_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ticker_data):\n",
    "    # Ensure 'Close', 'SMA_20', and 'RSI' columns are present\n",
    "    ticker_data = ticker_data[['Close', 'SMA_20', 'RSI']].dropna()\n",
    "    \n",
    "    # Prepare feature matrix X and target vector y\n",
    "    X = ticker_data[['SMA_20', 'RSI']]\n",
    "    y = pd.Series(np.where(ticker_data['Close'].shift(-1) > ticker_data['Close'], 1, 0), index=X.index)  # Binary classification for stock price movement\n",
    "    \n",
    "    # Split into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 20% validation split\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train Models for Each Stock Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_backtests = {}\n",
    "\n",
    "for ticker in symbols:\n",
    "    print(f\"Training models for {ticker}\")\n",
    "    ticker_data = stock_data[ticker]\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(ticker_data)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled, X_val_scaled, X_test_scaled = scale_features(X_train, X_val, X_test)\n",
    "    \n",
    "    # Train models\n",
    "    rf_model, rf_accuracy, rf_report = train_random_forest(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "    xgb_model, xgb_accuracy, xgb_report = train_xgboost(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "    lstm_model, lstm_accuracy, lstm_report = train_lstm_model(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "    \n",
    "    # Print model results\n",
    "    print(f\"Random Forest Validation Accuracy for {ticker}: {rf_accuracy}\")\n",
    "    print(f\"XGBoost Validation Accuracy for {ticker}: {xgb_accuracy}\")\n",
    "    print(f\"LSTM Validation Accuracy for {ticker}: {lstm_accuracy}\")\n",
    "    \n",
    "    # ## 7. Backtesting the Models\n",
    "    \n",
    "    # Generate signals for the test set\n",
    "    rf_signals = pd.Series(rf_model.predict(X_test), index=ticker_data.index[-len(X_test):])\n",
    "    xgb_signals = pd.Series(xgb_model.predict(X_test), index=ticker_data.index[-len(X_test):])\n",
    "\n",
    "    X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    lstm_predictions = lstm_model.predict(X_test_reshaped).flatten()\n",
    "    lstm_signals = pd.Series((lstm_predictions > 0.5).astype(int), index=ticker_data.index[-len(X_test):])\n",
    "\n",
    "    # Backtest the models\n",
    "    rf_backtest = backtest_strategy(ticker_data.copy(), rf_signals)\n",
    "    xgb_backtest = backtest_strategy(ticker_data.copy(), xgb_signals)\n",
    "    lstm_backtest = backtest_strategy(ticker_data.copy(), lstm_signals)\n",
    "    \n",
    "    # Store the backtest results\n",
    "    all_backtests[ticker] = {'RandomForest': rf_backtest, 'XGBoost': xgb_backtest, 'LSTM': lstm_backtest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
